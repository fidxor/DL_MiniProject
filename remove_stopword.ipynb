{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 원본 데이터 \n",
    "df = pd.read_csv('./data/MBTI 500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MBTI별 분류한 모든데이터 원본데이터는 제외\n",
    "totaldf = pd.DataFrame({'posts' : [], 'type' : [], 'type2' : []})\n",
    "def mbtipart(lst):\n",
    "    global totaldf \n",
    "\n",
    "    for alpha in lst:\n",
    "        newdf = df[df['type'].str.contains(alpha)]\n",
    "        newdf['type2'] = alpha\n",
    "\n",
    "        totaldf = pd.concat([totaldf, newdf])\n",
    "\n",
    "mbtipart(['I', 'E', 'S', 'N', 'T', 'F', 'J', 'P']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def stopword_process(text, wordslst : list):\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend([\"mbti\", \"infj\", \"intj\", \"infp\", \"intp\", \"enfj\", \"entj\", \"enfp\", \"entp\",\n",
    "                        \"isfj\", \"istj\", \"isfp\", \"istp\", \"esfj\", \"estj\", \"esfp\", \"estp\", \"personality\", \"type\"])\n",
    "    stop_words.extend(['like', 'think', 'people', 'get', 'thing', 'make', 'know', 'feel', 'one', 'go'])\n",
    "    stop_words.extend(wordslst)\n",
    "\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    changepost = ' '.join(s for s in tokens)    \n",
    "    \n",
    "    return changepost\n",
    "\n",
    "stop_word_df = pd.DataFrame({'posts' : [], 'type' : [], 'type2' : []})\n",
    "\n",
    "def duplication_words_remove(MBTI, wordslst):\n",
    "    global stop_word_df\n",
    "    temp_totaldf = totaldf[totaldf['type2'].str.contains(MBTI[0]) | totaldf['type2'].str.contains(MBTI[1])]\n",
    "\n",
    "    temp_totaldf['posts'] = temp_totaldf['posts'].apply(stopword_process, args = (wordslst, ))\n",
    "\n",
    "    stop_word_df = pd.concat([stop_word_df, temp_totaldf])\n",
    "\n",
    "\n",
    "MBTIlst = [['I', 'E'], \n",
    "           ['S', 'N'],\n",
    "           ['T', 'F'],\n",
    "           ['J', 'P']]\n",
    "\n",
    "remove_words = [['feel', 'time', 'say', 'good', 'would', 'really', 'want', 'way', 'see'],\n",
    "                 ['know', 'time', 'really', 'good', 'feel', 'want', 'see', 'way', 'also'],\n",
    "                 ['know', 'make', 'really', 'time', 'say', 'good', 'would', 'want', 'way', 'see'],\n",
    "                ['say', 'time', 'good', 'would', 'really', 'want', 'way', 'see', 'also']]\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    duplication_words_remove(MBTIlst[i], remove_words[i])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word_df.to_csv('MBTI_remove_stopword.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
