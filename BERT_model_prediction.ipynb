{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(1024, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=1024, out_features=16, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load('./data/model/largemodel_sample1000_epoch12.pt', map_location=torch.device('cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "labels = {\"INFJ\" : 0, \"INTJ\" : 1, \"INFP\" : 2, \"INTP\" : 3, \"ENFJ\" : 4, \"ENTJ\" : 5,\n",
    "              \"ENFP\" : 6, \"ENTP\" : 7, \"ISFJ\" : 8, \"ISTJ\" : 9, \"ISFP\" : 10, \"ISTP\" : 11,\n",
    "                \"ESFJ\" : 12, \"ESTJ\" : 13, \"ESFP\" : 14, \"ESTP\" : 15}\n",
    "\n",
    "# 결과 출력을 위해 labels key와 value 바꿔주기\n",
    "resultLabels = {v:k for k,v in labels.items()}\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['type']]\n",
    "        self.texts = [tokenizer(text,\n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['posts']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def prediction(model, text):\n",
    "    #특수 문자 제거\n",
    "    text_rmv = re.sub('[-=+,#/\\?:^.@*\\\"※~ㆍ!』‘|\\(\\)\\[\\]`\\'…》\\”\\“\\’·]', ' ', text)\n",
    "    # 공백 한개로 만들기\n",
    "    new_str = ' '.join(text_rmv.split())\n",
    "    # 임의의 dataframe으로 만들기\n",
    "    text_dict = {'posts': [new_str], 'type' : ['INTP']}\n",
    "    test_data = pd.DataFrame(text_dict)\n",
    "\n",
    "    #훈련 모델에 맞는 Dataset으로 변환\n",
    "    test = Dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              predicted = output.argmax(dim=1)\n",
    "\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from googletrans import Translator\n",
    "\n",
    "# 입력된 텍스트가 한글인지 영어인지 판단해서 한글이 하나라도 있으면 영어로 변역한다.\n",
    "def isKorean(input_s):\n",
    "    k_count = 0\n",
    "    e_count = 0\n",
    "    for c in input_s:\n",
    "        if ord('가') <= ord(c) <= ord('힣'):\n",
    "            k_count+=1\n",
    "        elif ord('a') <= ord(c.lower()) <= ord('z'):\n",
    "            e_count+=1\n",
    "\n",
    "    return k_count > 0\n",
    "\n",
    "# 한글에서 영어로 번역\n",
    "def languageTrans(text):\n",
    "    translator = Translator()\n",
    "\n",
    "    translation = translator.translate(text, dest = 'en')\n",
    "\n",
    "    return translation.text\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels = {\"INFJ\" : 0, \"INTJ\" : 1, \"INFP\" : 2, \"INTP\" : 3, \"ENFJ\" : 4, \"ENTJ\" : 5,\n",
    "              \"ENFP\" : 6, \"ENTP\" : 7, \"ISFJ\" : 8, \"ISTJ\" : 9, \"ISFP\" : 10, \"ISTP\" : 11,\n",
    "                \"ESFJ\" : 12, \"ESTJ\" : 13, \"ESFP\" : 14, \"ESTP\" : 15}\n",
    "\n",
    "INTP    24961\n",
    "INTJ    22427\n",
    "INFJ    14963\n",
    "INFP    12134\n",
    "ENTP    11725\n",
    "ENFP     6167\n",
    "ISTP     3424\n",
    "ENTJ     2955\n",
    "ESTP     1986\n",
    "ENFJ     1534\n",
    "ISTJ     1243\n",
    "ISFP      875\n",
    "ISFJ      650\n",
    "ESTJ      482\n",
    "ESFP      360\n",
    "ESFJ      181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFP\n"
     ]
    }
   ],
   "source": [
    "input_text = input('뭐든 입력해봐')\n",
    "\n",
    "if isKorean(input_text):\n",
    "    input_text = languageTrans(input_text)\n",
    "\n",
    "predicted = prediction(model, input_text)\n",
    "\n",
    "print(resultLabels.get(predicted.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
